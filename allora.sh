#!/bin/bash

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
log_message() {
    echo -e "\e[32m$1\e[0m"
}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
run_command() {
    local command="$1"
    local error_message="$2"
    
    log_message "–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è: $command"
    if eval "$command"; then
        log_message "–£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: $command"
    else
        log_message "$error_message"
        exit 1
    fi
}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ Docker
restart_docker() {
    log_message "–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º Docker..."
    run_command "sudo systemctl restart docker" "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å Docker. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ Docker."
}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
clone_repository() {
    local repo_url="$1"
    local target_dir="$2"
    
    if [ -d "$target_dir" ]; then
        log_message "–£–¥–∞–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ $target_dir..."
        rm -rf "$target_dir"
    fi
    
    run_command "git clone $repo_url $target_dir" "–ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π $repo_url"
}

# –õ–æ–≥–æ—Ç–∏–ø
echo -e '\e[32m'
echo -e '‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó '
echo -e '‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó'
echo -e '‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù'
echo -e '‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó'
echo -e '‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë'
echo -e '‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù'
echo -e '\e[0m'

echo -e "\n–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∫–∞–Ω–∞–ª may.crypto{ü¶Ö} —á—Ç–æ–±—ã –±—ã—Ç—å –≤ –∫—É—Ä—Å–µ —Å–∞–º—ã—Ö –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–¥ - https://t.me/maycrypto\n"

sleep 2

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –º–µ–Ω—é
while true; do
    echo "1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–æ–¥—É Allora"
    echo "2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏ –Ω–æ–¥—ã Allora"
    echo "3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–æ–¥—ã Allora"
    echo "4. –í—ã–π—Ç–∏ –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞"
    read -p "–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é: " option

    case $option in
        1)
            log_message "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–æ–≤..."
            run_command "sudo apt update && sudo apt upgrade -y" "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞–∫–µ—Ç—ã."
            run_command "sudo apt install ca-certificates zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev curl git wget make jq build-essential pkg-config lsb-release libssl-dev libreadline-dev libffi-dev gcc screen unzip lz4 -y" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã."

            log_message "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python..."
            run_command "sudo apt install python3 -y" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Python."

            log_message "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ pip3..."
            run_command "sudo apt install python3-pip -y" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å pip3."

            log_message "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker..."
            run_command "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg && echo 'deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable' | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null && sudo apt-get update && sudo apt-get install docker-ce docker-ce-cli containerd.io -y" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Docker."

            log_message "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker Compose..."
            run_command "sudo apt-get install docker-compose -y" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Docker Compose."

            log_message "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ GO..."
            run_command "sudo rm -rf /usr/local/go && curl -L https://go.dev/dl/go1.22.4.linux-amd64.tar.gz | sudo tar -xzf - -C /usr/local && echo 'export PATH=\$PATH:/usr/local/go/bin:\$HOME/go/bin' >> \$HOME/.bash_profile && echo 'export PATH=\$PATH:\$(go env GOPATH)/bin' >> \$HOME/.bash_profile && source \$HOME/.bash_profile" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å GO."

            log_message "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Allorad Wallet..."
            clone_repository "https://github.com/allora-network/allora-chain.git" "allora-chain"
            run_command "cd allora-chain && make all" "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Allorad Wallet."

            log_message "–ó–∞–ø—Ä–æ—Å Seed Phrase —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è..."
            run_command "allorad keys add testkey --recover" "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—Ä–æ—Å–∏—Ç—å Seed Phrase."

            log_message "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Allora Worker..."
            run_command "cd \$HOME"
            run_command "git clone https://github.com/allora-network/allora-huggingface-walkthrough"
            run_command "cd allora-huggingface-walkthrough"
            run_command "mkdir -p worker-data"
            run_command "chmod -R 777 worker-data"

            rm -rf config.json
            
            # –ó–∞–ø—Ä–æ—Å Seed Phrase
            read -p "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à—É Seed Phrase: " seed_phrase

            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ config.json
            cat <<EOF > config.json
{
    "wallet": {
        "addressKeyName": "testkey",
        "addressRestoreMnemonic": "$seed_phrase",
        "alloraHomeDir": "/root/.allorad",
        "gas": "1000000",
        "gasAdjustment": 1.0,
        "nodeRpc": "https://allora-testnet-1-rpc.testnet.nodium.xyz/",
        "maxRetries": 1,
        "delay": 1,
        "submitTx": false
    },
    "worker": [
        {
           "topicId": 1,
           "inferenceEntrypointName": "api-worker-reputer",
           "loopSeconds": 1,
           "parameters": {
               "InferenceEndpoint": "http://inference:8000/inference/{Token}",
               "Token": "ETH"
           }
       },
       {
           "topicId": 3,
           "inferenceEntrypointName": "api-worker-reputer",
           "loopSeconds": 5,
           "parameters": {
               "InferenceEndpoint": "http://inference:8000/inference/{Token}",
               "Token": "BTC"
           }
       },
       {
           "topicId": 5,
           "inferenceEntrypointName": "api-worker-reputer",
           "loopSeconds": 4,
           "parameters": {
               "InferenceEndpoint": "http://inference:8000/inference/{Token}",
               "Token": "SOL"
           }
       },
       {
           "topicId": 7,
           "inferenceEntrypointName": "api-worker-reputer",
           "loopSeconds": 2,
           "parameters": {
               "InferenceEndpoint": "http://inference:8000/inference/{Token}",
               "Token": "ETH"
           }
       },
       {
           "topicId": 8,
           "inferenceEntrypointName": "api-worker-reputer",
           "loopSeconds": 3,
           "parameters": {
               "InferenceEndpoint": "http://inference:8000/inference/{Token}",
               "Token": "BNB"
           }
       },
       {
           "topicId": 9,
           "inferenceEntrypointName": "api-worker-reputer",
           "loopSeconds": 5,
           "parameters": {
               "InferenceEndpoint": "http://inference:8000/inference/{Token}",
               "Token": "ARB"
           }
       }
       
   ]
}
EOF

            rm -rf app.py
            
            # –ó–∞–ø—Ä–æ—Å Api
            read -p "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à API: " api_coin

            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ app.py
            cat <<EOF > app.py
            
from flask import Flask, Response
import requests
import json
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# create our Flask app
app = Flask(__name__)

def get_coingecko_url(token):
    base_url = "https://api.coingecko.com/api/v3/coins/"
    token_map = {
        'ETH': 'ethereum',
        'SOL': 'solana',
        'BTC': 'bitcoin',
        'BNB': 'binancecoin',
        'ARB': 'arbitrum'
    }
    
    token = token.upper()
    if token in token_map:
        url = f"{base_url}{token_map[token]}/market_chart?vs_currency=usd&days=1&interval=minute"
        return url
    else:
        raise ValueError("Unsupported token")

def prepare_data(df):
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(df["y"].values.reshape(-1, 1))

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    sequence_length = 60
    X = []
    y = []
    for i in range(sequence_length, len(scaled_data)):
        X.append(scaled_data[i-sequence_length:i, 0])
        y.append(scaled_data[i, 0])
    X, y = np.array(X), np.array(y)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º—É [samples, time steps, features]
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))

    return X, y, scaler

def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))
    model.add(LSTM(units=50, return_sequences=False))
    model.add(Dense(units=1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# define our endpoint
@app.route("/inference/<string:token>")
def get_inference(token):
    """Generate inference for given token."""
    try:
        # Get the data from Coingecko
        url = get_coingecko_url(token)
    except ValueError as e:
        return Response(json.dumps({"error": str(e)}), status=400, mimetype='application/json')

    headers = {
        "accept": "application/json",
        "x-cg-demo-api-key": "CG-XXXXXXXXXXXXXXXXXXXXXX"  # Replace with your API key
    }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = response.json()
        df = pd.DataFrame(data["prices"])
        df.columns = ["ds", "y"]
        df["ds"] = pd.to_datetime(df["ds"], unit='ms')
        print(df.tail(5))
    else:
        return Response(json.dumps({"Failed to retrieve data from the API": str(response.text)}),
                        status=response.status_code,
                        mimetype='application/json')

    # Prepare data for LSTM
    X, y, scaler = prepare_data(df)

    # Build and train the LSTM model
    model = build_lstm_model((X.shape[1], 1))
    model.fit(X, y, epochs=5, batch_size=32, verbose=1)

    # Make a forecast for the next 10-20 minutes
    last_sequence = df["y"].values[-60:].reshape(-1, 1)
    last_sequence_scaled = scaler.transform(last_sequence)
    X_new = np.array([last_sequence_scaled])
    X_new = np.reshape(X_new, (X_new.shape[0], X_new.shape[1], 1))

    predicted_value_scaled = model.predict(X_new)
    predicted_value = scaler.inverse_transform(predicted_value_scaled)

    forecasted_value = predicted_value[0, 0]
    print(forecasted_value)  # Print the forecasted value

    return Response(str(forecasted_value), status=200)

# run our Flask app
if __name__ == '__main__':
    app.run(host="0.0.0.0", port=8000, debug=True)

EOF

            rm -rf requirements.txt
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ requirements.txt
            cat <<EOF > requirements.txt
flask[async]
gunicorn[gthread]
transformers[torch]
pandas
torch==2.0.1 
python-dotenv
requests==2.31.0
plotly
prophet
tensorflow==2.12.0
scikit-learn

EOF

            log_message "–ó–∞–ø—É—Å–∫ Allora Worker..."
            chmod +x init.config
            ./init.config
            cd ~/allora-huggingface-walkthrough
            
            docker compose up -d --build
            ;;
        2)
            log_message "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤... –î–ª—è –≤—ã—Ö–æ–¥–∞ –≤ –º–µ–Ω—é —Å–∫—Ä–∏–ø—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –∫–ª–∞–≤–∏—à CTRL+C"
            sleep 10
            run_command "docker compose logs -f worker" "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≤–µ—Å—Ç–∏ –ª–æ–≥–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ Docker."
            ;;
        3)
            log_message "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω—ã Ethereum —á–µ—Ä–µ–∑ –Ω–æ–¥—É..."
            response=$(curl -s http://localhost:8000/inference/ETH)
            if [ -z "$response" ]; then
                log_message "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É ETH. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–æ–¥—ã."
            else
                log_message "–¶–µ–Ω–∞ ETH: $response"
            fi
            ;;
        4)
            log_message "–í—ã—Ö–æ–¥ –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞."
            exit 0
            ;;
        *)
            log_message "–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            ;;
    esac
done
